{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alicelindel3/master/blob/main/Section_06/svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StHBIInDHOFT"
      },
      "source": [
        "# サポートベクターマシン\n",
        "サポートベクターマシン（Support Vector Machine、SVM）とは、パターン識別のための教師あり機械学習の手法です。  \n",
        "「マージン最大化」というアイディアに基づいているのですが、しばしば優れたパターン識別能力を発揮します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAorbtQWXtgE"
      },
      "source": [
        "## ●サポートベクターマシンとは？  \n",
        "簡単にするために、2つの特徴量を持つデータを2つのグループに分類する絵を使います。\n",
        "\n",
        "**（図: サポートベクターマシンの概念）**\n",
        "\n",
        "サポートベクターマシンとは、グループを明確に分ける境界線を引くための手法です。  \n",
        "こちらの図の例では、赤と青のクラスを明確に分ける境界線を引いています。  \n",
        "\n",
        "この図で特徴量は2つ（２次元）なので境界は線になりますが、3次元の場合は境界は面になります。  \n",
        "数学的に、直線や平面を一般化とした概念に「超平面」があります。  \n",
        "線形サポートベクターマシンでは、この超平面を使ってn次元のデータの境界を定めます。  \n",
        "\n",
        "上の図における直線の引き方ですが、「マージン最大化」により決定されます。  \n",
        "この場合のマージンは、境界となる線からもっとも近い点との距離のことです。  \n",
        "この場合は、赤と青それぞれのグループから線に最も近い2つずつの点のマージンを最大化するように線を引いています。  \n",
        "このようなマージンの最大化に使われる境界付近の点を、サポートベクトルと呼びます。\n",
        "マージンを最大化するために、赤のグループからも青のグループからももっとも遠い境界線を引くことになります。  \n",
        "\n",
        "この境界線は「分類器」として機能し、新しいデータがどちらのグループに属するかを判別することができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTWQ-vdIgF0x"
      },
      "source": [
        "## ●データセットの読み込み\n",
        "今回は、scikit-learnに含まれるワインのデータセットを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSIAHXrCF0Af"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine = load_wine()\n",
        "wine_df = pd.DataFrame(wine.data, columns=wine.feature_names)  # data: 説明変数\n",
        "wine_df[\"class\"] = wine.target  # target: 目的変数\n",
        "wine_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn1dXI0_WE3H"
      },
      "source": [
        "データセットの説明を表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKRfxGGYiZVW"
      },
      "source": [
        "print(wine.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHoJvcxfWVy9"
      },
      "source": [
        "各統計量を表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKwNlDMdjOcY"
      },
      "source": [
        "wine_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFvklrq6WeRa"
      },
      "source": [
        "ライブラリseabornの`pairplot`により、説明変数同士、及び説明変数と目的変数の関係を一覧表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do9NPhv_lRBy"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.pairplot(wine_df, hue=\"class\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJG8oUcYk5Gh"
      },
      "source": [
        "## ●SVMの実装\n",
        "サポートベクターマシンを使い、ワインの分類を行います。  \n",
        "まずは、データセットを訓練用のデータとテスト用のデータに分割し、標準化します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s863YjtLirbM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 訓練データとテストデータに分割\n",
        "x_train, x_test, t_train, t_test = train_test_split(wine.data, wine.target, random_state=0) \n",
        "\n",
        "# データの標準化\n",
        "std_scl = StandardScaler()\n",
        "std_scl.fit(x_train)\n",
        "x_train = std_scl.transform(x_train)\n",
        "x_test = std_scl.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCkDkZnZoW6c"
      },
      "source": [
        "今回は、線形サポートベクターマシンを使い、超平面によりデータを分類します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuWppYA_oWLD"
      },
      "source": [
        "from sklearn.svm import LinearSVC  # 線形ベクターマシン\n",
        "\n",
        "model = LinearSVC(random_state=0)\n",
        "\n",
        "# 全ての説明変数を使い学習\n",
        "model.fit(x_train, t_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns0IkfFSyP8i"
      },
      "source": [
        "訓練済みのモデルを使い、訓練データ及びテストデータで予測を行います。  \n",
        "そして、その正解率を測定します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksPOw4gyqzDO"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 予測結果\n",
        "y_train = model.predict(x_train)\n",
        "y_test = model.predict(x_test)\n",
        "print(y_train, y_test)\n",
        "\n",
        "# 正解率\n",
        "acc_train = accuracy_score(t_train, y_train)\n",
        "acc_test = accuracy_score(t_test, y_test)\n",
        "print(acc_train, acc_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdXP0yzMyhSV"
      },
      "source": [
        "全てのデータのグループ分け結果を、グラフ表示します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gs2EVkvtncX"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "axis_1 = 0\n",
        "axis_2 = 1\n",
        "\n",
        "x = np.concatenate([x_train, x_test])\n",
        "y = np.concatenate([y_train, y_test])\n",
        "t = np.concatenate([t_train, t_test])\n",
        "\n",
        "# 0にクラス分類されたグループ\n",
        "group_0 = x[y==0]\n",
        "plt.scatter(group_0[:, axis_1], group_0[:, axis_2], c=\"blue\")\n",
        "\n",
        "# 1にクラス分類されたグループ\n",
        "group_1 = x[y==1]\n",
        "plt.scatter(group_1[:, axis_1], group_1[:, axis_2], c=\"red\")\n",
        "\n",
        "# 2にクラス分類されたグループ\n",
        "group_2 = x[y==2]\n",
        "plt.scatter(group_2[:, axis_1], group_2[:, axis_2], c=\"green\")\n",
        "\n",
        "plt.xlabel(wine.feature_names[axis_1])\n",
        "plt.ylabel(wine.feature_names[axis_2])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAy6JF5Vy5rG"
      },
      "source": [
        "なお、結果はハイパーパラーメータを調整することで変化します。  \n",
        "例えば、LinearSVCの引数として渡すことが可能なハイパーパラメータCは、正則化のためのパラメータです。  \n",
        "この値を大きくすれば、誤分類によるペナルティが大きくなり、境界が複雑になります。  \n",
        "ハイパーパラーメータについては、以下の公式ドキュメントを参考にしてください。  \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
      ]
    }
  ]
}